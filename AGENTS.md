# Agent Guidelines for Azure MCP Server (Python)

This document provides essential context for AI coding assistants working on this project.

## Quick Context

- **What**: Python MCP server providing Azure tools for AI assistants
- **Why**: Team prefers Python, need features Microsoft doesn't provide (Cost, Entra ID)
- **Based on**: Microsoft's .NET Azure MCP Server (reimplemented, not ported)

## Core Principles

1. **Use Resource Graph** for listing resources (not management API)
2. **Pydantic everywhere** for options validation and schema generation
3. **Async/await** for all Azure operations
4. **Async-first SDKs** - Use `.aio` modules when available; wrap sync with `asyncio.to_thread()` otherwise
5. **Handle errors** with `handle_azure_error()` wrapper
6. **Register tools** with `@register_tool("family", "subgroup")` decorator
7. **AI Foundry compatible schemas** - NO `str | None` or `list | None` patterns (see below)
8. **Use fastmcp** for MCP server (`fastmcp>=2.14.0`)
9. **⚠️ CHECK BASE CLASS FIRST** - Always use `AzureService` methods before implementing SDK calls directly. Run `pytest tests/unit/test_architecture_patterns.py` to validate.

## ⚠️ AI Foundry Schema Compatibility

Azure AI Foundry does NOT support these JSON Schema features:
- `anyOf`, `allOf`, `oneOf` (generated by `Optional` types)
- `$ref`, `$defs` (generated by nested Pydantic models)

Pydantic generates these for optional types. **ALWAYS use these patterns:**

```python
# ❌ WRONG - generates anyOf, breaks AI Foundry
resource_group: str | None = Field(default=None, description="...")
parameters: list[dict] | None = Field(default=None, description="...")

# ✅ CORRECT - simple types, AI Foundry compatible  
resource_group: str = Field(default="", description="... Leave empty for all.")
parameters: list[dict[str, Any]] = Field(default_factory=list, description="...")
```

See `docs/ai-foundry-deployment.md` for full details.

## Adding a Tool (Quick Reference)

```python
# src/azure_mcp/tools/{family}/{action}.py

from pydantic import BaseModel, Field
from azure_mcp.core.base import AzureService, AzureTool
from azure_mcp.core.errors import handle_azure_error
from azure_mcp.core.models import ToolMetadata
from azure_mcp.core.registry import register_tool

class MyOptions(BaseModel):
    subscription: str = Field(..., description="Subscription ID or name")
    # Use str = "" for optional strings (NOT str | None)
    resource_group: str = Field(default="", description="Filter by RG. Leave empty for all.")

class MyService(AzureService):
    async def do_work(self, subscription: str, resource_group: str = ""):
        sub_id = await self.resolve_subscription(subscription)
        return await self.list_resources("Microsoft.Type/resources", sub_id)

@register_tool("family", "subgroup")
class MyTool(AzureTool):
    @property
    def name(self) -> str: return "family_resource_action"
    
    @property
    def description(self) -> str: return "What this tool does"
    
    @property
    def options_model(self): return MyOptions
    
    async def execute(self, options):
        try:
            return await MyService().do_work(options.subscription, options.resource_group)
        except Exception as e:
            raise handle_azure_error(e)
```

## Naming: `{family}_{resource}_{action}`

- `cost_query`, `cost_forecast`, `cost_budgets_list`
- `entraid_user_list`, `entraid_group_members`
- `storage_blob_read`, `cosmos_item_query`

## Priority Order

1. **Cost Management** (Issues #22-28) - NEW FEATURES ⭐
2. **Entra ID** (Issues #29-38) - NEW FEATURES ⭐
3. Storage, Cosmos, Key Vault, etc.

## Key Files

- `src/azure_mcp/core/base.py` - Base classes
- `src/azure_mcp/core/registry.py` - Tool registration
- `docs/adding-tools.md` - Detailed guide
- `docs/ai-foundry-deployment.md` - AI Foundry deployment & schema guide
- `.github/copilot-instructions.md` - Full agent instructions
- `.github/ISSUES.md` - All 59 planned issues

## Don't Forget

- Import new tool modules in `tools/__init__.py`
- Add tests in `tests/unit/tools/`
- Use `ToolMetadata(read_only=False, requires_confirmation=True)` for write ops
- **Use `str = ""` NOT `str | None`** for optional fields (AI Foundry compatibility)
- **Use `.aio` SDK modules** when available for non-blocking I/O (see `docs/adding-tools.md`)
- Run `pytest tests/unit/test_schema_compatibility.py` to verify schemas
- Run `pytest tests/unit/test_architecture_patterns.py` to validate patterns
- **Use base class methods** (`execute_resource_graph_query()`, `resolve_subscription()`, `get_credential()`) - never instantiate SDK clients directly

## ⚠️ CRITICAL: Deployment Checklist

When adding a new tool family (e.g., `search`, `keyvault`), you **MUST** complete these steps:

### 1. Update Dockerfile (REQUIRED!)

Add your new extra to the `pip install` line in `Dockerfile`:

```dockerfile
# ❌ BEFORE - missing new 'search' extra
RUN pip install --no-cache-dir ".[cosmos,cost,storage,entra,monitor,rbac,communication]" uvicorn starlette

# ✅ AFTER - includes new 'search' extra  
RUN pip install --no-cache-dir ".[cosmos,cost,storage,entra,monitor,rbac,communication,search]" uvicorn starlette
```

**This is forgotten frequently!** Without this, the deployed MCP will fail with `ModuleNotFoundError`.

### 2. Update RBAC Allowed Roles (if needed)

If your tools need data plane access (most do), add roles to `src/azure_mcp/tools/rbac/service.py`:

```python
ALLOWED_RBAC_ROLES: set[str] = {
    # ... existing roles ...
    # Azure AI Search - Data Plane (example)
    "Search Index Data Reader",
    "Search Index Data Contributor",
}
```

### 3. Document Required Permissions

The MCP's Managed Identity needs permissions to use your tools. Document what roles are needed:

| Service | Required Role | Scope |
|---------|---------------|-------|
| Azure AI Search | Search Index Data Reader | Search Service |
| Cosmos DB | Cosmos DB Built-in Data Reader | Cosmos Account |
| Storage | Storage Blob Data Reader | Storage Account |
| Key Vault | Key Vault Secrets User | Key Vault |

**Note**: The MCP cannot assign roles to itself. Users must pre-assign these roles or use a bootstrap script.

